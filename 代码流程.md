# 1. 合并excel

```python
import pandas as pd
import os

def Concat_excle(dir):  #https://blog.csdn.net/fffflyinthesky/article/details/107695833
    frames = []
    for root, dirs, files in os.walk(dir):
        # print(files)
        for file in files:
            if os.path.splitext(file)[1] == '.xlsx':
                # print(file)
                # print(os.path.join(root,file))
                df = pd.read_excel(os.path.join(root,file), None)
                keys = list(df.keys())
                # print(keys)
                for i in keys:
                    df_sheet = df[i]
                    frames.append(df_sheet) #将所有df更新进frame表中     
    result = pd.concat(frames) 
    result.drop_duplicates(subset=None, keep='first', inplace=True)#删除重复的值，这里subset='昵称'表示每个用户只取评论的一条，要删除重复的评论改为None即可
    result.sort_values("时间",inplace=True)# 按时间进行排序
# print(pd.concat(frames))
#将合并后的dataframe存为Excel文件，保存时去除索引
    result.to_excel((os.path.abspath(os.path.join(dir,"..",'./被处理的excel'))) + '/所有迪士尼评论.xls',index = False)
    # os.path.abspath是绝对路径，os.path.join(dir,"..")是dir的上一级路径
    # https://blog.csdn.net/longshenlmj/article/details/13294871
    
dir='/Users/nxcy/Desktop/自然语言处理数据/评论数据'
Concat_excle(dir)
```

==注释==：将要合并的所有的excel放到`dir='/Users/nxcy/Desktop/自然语言处理数据/评论数据'`这个文件夹里面。然后运行这个程序即可，生成的合并的文件存储路径为`dir`上一级目录下面的被处理的excel的文件夹内。只删除重复的评论，并按时间进行排序。

# 2. 过长评论剔除

```python
pd.read_excel('/Users/nxcy/Desktop/自然语言处理数据/被处理的excel/可被crf分词的句子.xls')
# 将要被筛选的excel放入这个路径即可
# 
```

'/Users/nxcy/Desktop/自然语言处理数据/被处理的excel/长度大于50的评论.xlsx'

'/Users/nxcy/Desktop/自然语言处理数据/被处理的excel/去除长度大于50的评论.xlsx'

这两个为输出路径

# 3. 统计词频

`/Users/nxcy/Desktop/自然语言处理数据/被处理的excel/所有迪士尼评论.xls`将这个==文件位置放好==，全部运行，即可生成`'/Users/nxcy/Desktop/自然语言处理数据/分词结果txt和json/统计词频和词性还有分数'`这个txt和json的文件。

# 4. 词语筛选

导入上一步统计出来的词语，json文件，然后导出的文件是一个txt，

==/Users/nxcy/Desktop/自然语言处理数据/分词结果txt和json/筛选后的情感词列表.txt==



# 5. 将词语分隔成为一个csv

1. 输入为`data1 = pd.read_excel('/Users/nxcy/Desktop/自然语言处理数据/被处理的excel/去除长度大于50的评论.xlsx')`     **就是对这个文件里面的评论进行分词**
2. `f = open("/Users/nxcy/Desktop/自然语言处理数据/分词结果txt和json/筛选后的情感词列表.txt","r")` 读取的是这个文件里面的情感词汇列表
3. 就相当于用文件2的词去分文件1里面的评论，然后筛选出来形成csv