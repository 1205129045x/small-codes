### 代码1
- **读取评论**（用自己定义的函数导入excel）
- **讲评论进行分类，有一些含有表情的句子无法被CRF分词导出为excel**（也是用自己定义的[函数](/Users/nxcy/Desktop/函数说明.md)）
- **词频词性**

### 代码2

- **合并之前每个月爬的评论，评论存放路径为<u>/Users/nxcy/Desktop/自然语言处理数据/评论数据</u>**

- **合并完之后，导出名为<u>所有迪士尼评论.xlsx</u>的文件，存储目录为<u>/Users/nxcy/Desktop/自然语言处理数据</u>**

- **处理完后发现一些问题** ==有些用户恶意刷评论，发布评论的时间很短，一个人有多个评论==

- 对于这个问题的处理的话，假如只保留每个用户的一条评论的话，那么一半的评论都会被删除，先做一个比较吧，删除和不删除做对比。代码3

### 代码3

- **对评论按长度进行分类**
- **过长的评论删掉存到另一个表格中**

### 代码4（==词语选择==）

在做的时候我想到：输出词性含有*‘ns’*的词语的时候，会出现很多地名，其中有一些是迪士尼的景点地名，所以我在做的时候是不是就可以首先就自己保留这些地名，然后在做关联规则的时候就讲这些地名统一替换为迪士尼旅游景点或者景点。最好是能够关联的时候同时将他们识别为一类词，有结果的时候又能知道这个词原来对应的是什么词。



==做这一部分的时候还可以想想==

- **导入词频json文件，统计有什么词性**
- [代码文件](/Users/nxcy/Documents/HanLP/my-nlp- processing/输出词性中含有某个词性的词语.ipynb)
- **给定一个词性，输出包含该词性的词语**
- 保留所有名词 所有形容词

1. 保留含有以下词性的词语
   - n 名词
   - a 形容词
   - i  成语
   -  成语
   
2. 删除只包含以下词性的词语 
	- ag  形容词性语素
	
	- dg  辄,俱,复之类的副词
	
	- Ng 名词性语素
	
	- Tg  时间词性语素
	
	- Vg 动词性语素
	
	- d 副词
	
	- j  简称略语
	
	- h  前缀
	
	- k  后缀
	
	- ~~m  数词~~==这里应该是只要含有m就删除==      但是有一些误删的，手动添加“很多”
	
	  好多 {'词性': {'m': 139, 'a': 2}有个形容词a可以添加假若含有a这个词性就给他添加进去多 {'词性': {'a': 780, 'ad': 131, 'm': 62, 'd': 11, 'v': 1},
	
	  棒 {'词性': {'a': 189, 'n': 69, 'd': 2, 'Ng': 26, 'Ag': 1, 'Vg': 1, 'm': 1, 'y': 1}, 
	
	  好多 {'词性': {'m': 139, 'a': 2}, '
	
	  太久 {'词性': {'a': 4, 'm': 5}, '
	
	  好久 {'词性': {'a': 7, 'd': 1, 'm': 1},
	
	- ~~q 量词~~删除含有q的词语，手动添加
	
	  美----{'词性': {'a': 173, 'j': 37, 'q': 1}, 
	
	  热门----{'词性': {'a': 94, 'n': 12, 'j': 2, 'q': 1}
	
	  加勒比海盗----{'词性': {'vn': 15, 'v': 41, 'n': 1, 'q': 1, 'nr': 1},
	
	- v 动词
	
	  **以下为词语里面含有推荐的词语**
	
	  推荐 +++++ {'词性': {'v': 318, 'vn': 13}, 'scores': {'5': 269, '4': 19, '0': 41, '3': 2}}
	  强烈推荐 +++++ {'词性': {'i': 21}, 'scores': {'5': 18, '0': 1, '4': 2}}
	  不推荐 +++++ {'词性': {'v': 15}, 'scores': {'5': 2, '3': 2, '1': 5, '4': 1, '2': 1, '0': 4}}
	  推荐海 +++++ {'词性': {'v': 3}, 'scores': {'5': 3}}
	  推荐哦 +++++ {'词性': {'v': 1}, 'scores': {'5': 1}}
	  之一.推荐 +++++ {'词性': {'r': 1}, 'scores': {'5': 1}}
	  推荐< +++++ {'词性': {'vn': 1}, 'scores': {'5': 1}}
	  极力推荐 +++++ {'词性': {'i': 1}, 'scores': {'5': 1}}
	  推荐噢 +++++ {'词性': {'v': 1}, 'scores': {'5': 1}}
	
	  ==根据只含有动词词性来进行筛选会删掉一些关键词，比如不推荐== **可以将这些词语统一成为推荐** *代码如下*
	
	
	```python
	data=pd.read_excel('/Users/nxcy/Desktop/评论保留情感词汇的分词结果.xlsx')
	data1=data.values.tolist()
	d=['推荐','强烈推荐','推荐海','推荐哦','之一.推荐','推荐< ']
	```
	
	
	
	
	- vd 副动词
	- vn 名动词
	
3. 删除含有以下词性的词语
   
   - b 区别词
   - c 连词
   - e 叹词
   - f  方位词
   - nrf 音译人名
   - o 拟声词
   - p 介词
   - r 代词
   - s 处所词
   - t  时间词
   - u  助词
   - w  标点符号
   - y  语气词
   - z 状态词
   
4. 以下不做处理

   - l 习用语

   - nf 食品

   - nnt 职务名称

   - nr 人名

   - ns 地名

   - nt  机构团体名 (发现有好多排队被分进去了，应该是因为最后一个字是队，所以被分成了机构团体名)

   - ntc 公司名 （其中现代一词也被分成了公司名）

   - ntcb （农业银行）

   - ntch（快捷酒店）

   - nx （都是一些英文，但是有PP FP这样的表示快速通道的意思的词，是一开始就讲他们提取出来吗？）不如直接手动添加 yyds fp pp 这类的词 ==还是全部删除掉好了==

#### ==手动添加被误删的词语==
- ​	 {'词性': {'v': 1246}
- 浪费 {'词性': {'v': 10}
- 带娃 {'词性': {'v': 64}, 
- 可玩性 {'词性': {'v': 11},
- 溜娃 {'词性': {'v': 11},
- 不推荐 {'词性': {'v': 15}, 
- 买不起 {'词性': {'v': 5},
- 解压 {'词性': {'v': 5}
- 有点累 {'词性': {'v': 7}
-  超喜欢 {'词性': {'v': 10},
- 买不起 {'词性': {'v': 5}

# 假如我只取词频很大的词做关联规则分析可以吗

# 想想怎么样可以把句子和句子的分词都保存在一个文件夹里面

# 可以做一个词频分布曲线，长尾效应，把后面尾部的词都删去，保留前面词频高的词语

